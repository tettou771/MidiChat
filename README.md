# MidiChat

これはopenFrameworksのプロジェクトです。

openFrameworks 0.11.2 を使って開発しています。

ChatGPT と Whisper を使って、自然言語でリクエストしてMIDIのシーケンスを作れます。使用するには、OpenAIのAPIキーが必要です。

あくまでも仮想MIDIデバイスに出力するため、単体では音が出ません。DAWなどを用意して信号を受け取ってください。

APIキーは、bin/data/config.json に書いてください。

使い方は manual/Manual.md を参照してください。

# Addons

- [ofxComponent](https://github.com/tettou771/ofxComponent)
- [ofxComponentUI](https://github.com/tettou771/ofxComponentUI)
- [ofxChatGPT](https://github.com/tettou771/ofxChatGPT)
- [ofxWhisper](https://github.com/tettou771/ofxWhisper)
- [ofxMidi](https://github.com/danomatika/ofxMidi)
- [ofxAudioFile](https://github.com/npisanti/ofxAudioFile)
- [ofxHttpUtils](https://github.com/arturoc/ofxHttpUtils)
- [ofxSoundObjects](https://github.com/roymacdonald/ofxSoundObjects)
- ofxOsc (openFrameworks のデフォルトアドオン)
- ofxPoco (openFrameworks のデフォルトアドオン)

# Author

[tettou771](https://github.com/tettou771)

# Lisence

MIT
